{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06053aab-2708-4605-ab52-273a70d47047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "# set seeds for reproducability\n",
    "# from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "# set_random_seed(2)\n",
    "# seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string, os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f677520-58d9-47bf-86e4-69fc226ffcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(article_df.headline.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "361d7bef-038a-41a8-9b77-82e2f54974aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_dir =r'C:\\Users\\jv028u\\OneDrive - Linde Group\\Desktop\\stats and ML\\Projects'\n",
    "\n",
    "all_headlines = []\n",
    "for filename in os.listdir(curr_dir):\n",
    "    if 'Articles' in filename:\n",
    "        article_df = pd.read_csv(curr_dir+ '\\\\' +filename)\n",
    "        all_headlines.extend(list(article_df.headline.values))\n",
    "        break\n",
    "\n",
    "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
    "len(all_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c582132-b42a-4ba1-a2fb-aa1e17b80118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finding an expansive view  of a forgotten people in niger', 'and now  the dreaded trump curse', 'venezuelas descent into dictatorship', 'stain permeates basketball blue blood', 'taking things for granted', 'the caged beast awakens', 'an everunfolding story', 'oreilly thrives as settlements add up', 'mouse infestation', 'divide in gop now threatens trump tax plan']\n"
     ]
    }
   ],
   "source": [
    "corpus = [] \n",
    "for headline in all_headlines:\n",
    "    cleaned_text = [] \n",
    "    for char in headline: \n",
    "        if char not in string.punctuation:\n",
    "            cleaned_text.append(char)\n",
    "    txt = \"\".join(cleaned_text).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\", \"ignore\")\n",
    "    corpus.append(txt) # Print first 10 entries from the corpus to verify\n",
    "print(corpus[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d90fd7-5235-4e1a-a7f0-64d9f0fb3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "#each word is assigned a unique integer token (index).\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "# print(corpus)\n",
    "total_words=len(tokenizer.word_index)+1\n",
    "\n",
    "# print(tokenizer.word_index)\n",
    "input_sequences=[]\n",
    "for line in corpus:\n",
    "    # Convert the line to a list of tokens\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    # print(token_list)  \n",
    "    for i in range(1,len(token_list)):\n",
    "        # Create N-gram sequences from the token list\n",
    "        n_gram_sequence=token_list[:i+1]\n",
    "        # print(n_gram_sequence)\n",
    "        input_sequences.append(n_gram_sequence)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abf6c7e4-1ae6-4b03-83e3-52714e965c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d464a3aa-d14c-4989-ab4a-6210a24b8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length=[]\n",
    "for x in input_sequences:\n",
    "    max_sequence_length.append(len(x))\n",
    "\n",
    "max_len=max(max_sequence_length)\n",
    "\n",
    "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_len,padding='pre'))\n",
    "predictor,label=input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label=ku.to_categorical(label,num_classes=total_words)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c24782c-01a8-4774-9655-26a45787622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69d63066-ecbe-46a2-aacc-2e749a6573d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_len=max_len-1\n",
    "# model=Sequential()\n",
    "\n",
    "# model.add(Embedding(total_words,10,input_length=input_len))\n",
    "# model.add(LSTM(100))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(total_words,activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86b4c42f-6af1-4b1e-a9de-4d9ed4abad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(predictors,label,epochs=100,verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce40b66b-5d26-4ba7-82db-a1db106a03c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "151/151 - 30s - 198ms/step - loss: 7.3997\n",
      "Epoch 2/100\n",
      "151/151 - 16s - 108ms/step - loss: 6.6310\n",
      "Epoch 3/100\n",
      "151/151 - 16s - 105ms/step - loss: 5.8861\n",
      "Epoch 4/100\n",
      "151/151 - 25s - 168ms/step - loss: 4.8188\n",
      "Epoch 5/100\n",
      "151/151 - 41s - 269ms/step - loss: 3.6212\n",
      "Epoch 6/100\n",
      "151/151 - 25s - 167ms/step - loss: 2.4406\n",
      "Epoch 7/100\n",
      "151/151 - 23s - 149ms/step - loss: 1.7400\n",
      "Epoch 8/100\n",
      "151/151 - 23s - 153ms/step - loss: 1.1712\n",
      "Epoch 9/100\n",
      "151/151 - 38s - 253ms/step - loss: 0.8477\n",
      "Epoch 10/100\n",
      "151/151 - 23s - 154ms/step - loss: 0.6836\n",
      "Epoch 11/100\n",
      "151/151 - 22s - 148ms/step - loss: 0.5712\n",
      "Epoch 12/100\n",
      "151/151 - 39s - 259ms/step - loss: 0.5220\n",
      "Epoch 13/100\n",
      "151/151 - 22s - 145ms/step - loss: 0.4832\n",
      "Epoch 14/100\n",
      "151/151 - 22s - 144ms/step - loss: 0.4569\n",
      "Epoch 15/100\n",
      "151/151 - 22s - 145ms/step - loss: 0.4450\n",
      "Epoch 16/100\n",
      "151/151 - 39s - 258ms/step - loss: 0.4187\n",
      "Epoch 17/100\n",
      "151/151 - 24s - 159ms/step - loss: 0.4210\n",
      "Epoch 18/100\n",
      "151/151 - 39s - 255ms/step - loss: 0.5024\n",
      "Epoch 19/100\n",
      "151/151 - 22s - 144ms/step - loss: 0.7822\n",
      "Epoch 20/100\n",
      "151/151 - 22s - 147ms/step - loss: 2.2424\n",
      "Epoch 21/100\n",
      "151/151 - 23s - 151ms/step - loss: 3.5606\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c3c2a72450>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(total_words, 128, input_length=max_len - 1))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=False)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "# Summary of the model\n",
    "# model.summary()\n",
    "# Early stopping to avoid overfitting\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "model.fit(predictor, label, epochs=100, verbose=2, callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafdf84a-94cd-4988-8309-b064fa4f4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        # print(token_list)\n",
    "        token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
    "        # print(token_list)\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        # print(predicted)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            # print(index,predicted)\n",
    "            if index == predicted:\n",
    "                # print(index)\n",
    "                # print(predicted)\n",
    "                # print(word)\n",
    "                output_word = word\n",
    "                # print(output_word)\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a05b2e5-79ef-4766-94a9-ebf0b7995822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "United States More Spice Back In Real\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Preident Trump Cant Withhold Funding And\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Donald Trump And Silence Back In\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "India And China Cant Brings Moment Are\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "New York Today Health Plan Dies\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Science And Technology Knocking On The Ground Battle\n"
     ]
    }
   ],
   "source": [
    "print (generate_text(\"united states\", 5, model, max_len))\n",
    "print (generate_text(\"preident trump\", 4, model, max_len))\n",
    "print (generate_text(\"donald trump\", 4, model, max_len))\n",
    "print (generate_text(\"india and china\", 4, model, max_len))\n",
    "print (generate_text(\"new york\", 4, model, max_len))\n",
    "print (generate_text(\"science and technology\", 5, model, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592660a-3947-4e90-b00c-56bad538bd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2bfb7-11f3-4bc3-82f3-273b404e2fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2205af-803c-415d-b61e-0c6e9600665b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870dc02-0c0d-4d92-9a15-45404946eb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
